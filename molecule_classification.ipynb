{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aadc30f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243c3d90",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ae412a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_DIR = 'database/output_files_OLD/'\n",
    "ANODYNE_FILE = 'anodyne_1-1000-ADMET-properties.csv'\n",
    "FDA_FILE = 'fda-ADMET-properties.csv'\n",
    "WNFDA_FILE = 'world-not-fda-ADMET-properties.csv'\n",
    "DATASET_FILE = 'dataset.csv'\n",
    "\n",
    "MAJORITY_CLASS = 'anodyne'\n",
    "MINORITY_CLASS = 'fda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561ebde5",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f383aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "anodyne_df = pd.read_csv(DB_DIR + ANODYNE_FILE)\n",
    "fda = pd.read_csv(DB_DIR + FDA_FILE)\n",
    "wnfda = pd.read_csv(DB_DIR + WNFDA_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac676f24",
   "metadata": {},
   "source": [
    "### Merge FDA and World-Not-FDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbe8a33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fda_df = pd.concat([fda, wnfda])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e11b7a",
   "metadata": {},
   "source": [
    "### Add labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "438ac8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fda_df['Label'] = MINORITY_CLASS\n",
    "anodyne_df['Label'] = MAJORITY_CLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4afe514",
   "metadata": {},
   "source": [
    "### Merge FDA and Anodyne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2c85222",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([fda_df, anodyne_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae815ce",
   "metadata": {},
   "source": [
    "### Remove 'Molecule' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c732f478",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Molecule', inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccc4926",
   "metadata": {},
   "source": [
    "### Show rows with at least one missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfb663d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Canonical SMILES</th>\n",
       "      <th>Formula</th>\n",
       "      <th>MW</th>\n",
       "      <th>#Heavy atoms</th>\n",
       "      <th>#Aromatic heavy atoms</th>\n",
       "      <th>Fraction Csp3</th>\n",
       "      <th>#Rotatable bonds</th>\n",
       "      <th>#H-bond acceptors</th>\n",
       "      <th>#H-bond donors</th>\n",
       "      <th>MR</th>\n",
       "      <th>...</th>\n",
       "      <th>Ghose #violations</th>\n",
       "      <th>Veber #violations</th>\n",
       "      <th>Egan #violations</th>\n",
       "      <th>Muegge #violations</th>\n",
       "      <th>Bioavailability Score</th>\n",
       "      <th>PAINS #alerts</th>\n",
       "      <th>Brenk #alerts</th>\n",
       "      <th>Leadlikeness #violations</th>\n",
       "      <th>Synthetic Accessibility</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Canonical SMILES, Formula, MW, #Heavy atoms, #Aromatic heavy atoms, Fraction Csp3, #Rotatable bonds, #H-bond acceptors, #H-bond donors, MR, TPSA, iLOGP, XLOGP3, WLOGP, MLOGP, Silicos-IT Log P, Consensus Log P, ESOL Log S, ESOL Solubility (mg/ml), ESOL Solubility (mol/l), ESOL Class, Ali Log S, Ali Solubility (mg/ml), Ali Solubility (mol/l), Ali Class, Silicos-IT LogSw, Silicos-IT Solubility (mg/ml), Silicos-IT Solubility (mol/l), Silicos-IT class, GI absorption, BBB permeant, Pgp substrate, CYP1A2 inhibitor, CYP2C19 inhibitor, CYP2C9 inhibitor, CYP2D6 inhibitor, CYP3A4 inhibitor, log Kp (cm/s), Lipinski #violations, Ghose #violations, Veber #violations, Egan #violations, Muegge #violations, Bioavailability Score, PAINS #alerts, Brenk #alerts, Leadlikeness #violations, Synthetic Accessibility, Label]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 49 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isnull().any(axis = 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c8920b",
   "metadata": {},
   "source": [
    "### Delete duplicate rows based on SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15dee8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['Canonical SMILES'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca50c93",
   "metadata": {},
   "source": [
    "### Delete duplicate rows based on all columns except SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f745d8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=df.columns.difference(['Canonical SMILES']), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5e2a0f",
   "metadata": {},
   "source": [
    "### Remove 'Canonical SMILES' and 'Formula' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca96604e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Canonical SMILES', inplace = True, axis = 1)\n",
    "df.drop('Formula', inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c9c3c1",
   "metadata": {},
   "source": [
    "### Convert categorical data using One-Hot-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ad4deb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['Label']\n",
    "df = df.drop('Label', axis = 1)\n",
    "\n",
    "caterogical_columns = df.select_dtypes(include=['object']).columns\n",
    "df = pd.get_dummies(df, columns = caterogical_columns, prefix = caterogical_columns)\n",
    "\n",
    "df = pd.concat([df, labels.rename('Label')], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c303ee",
   "metadata": {},
   "source": [
    "### Dump csv file function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bec6899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_df(path, f_name, df):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    df.to_csv(os.path.join(path, f_name), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae171af7",
   "metadata": {},
   "source": [
    "### Load csv file function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79e5e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(path, f_name):\n",
    "    return pd.read_csv(os.path.join(path, f_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6355195",
   "metadata": {},
   "source": [
    "### Save prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3438a586",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_df(DB_DIR, DATASET_FILE, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94c2d4b",
   "metadata": {},
   "source": [
    "# Train-Test-Validation splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3da9b51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4053d8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = 'dataset'\n",
    "TRAIN_F_NAME = 'train.csv'\n",
    "TEST_F_NAME = 'test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b216186e",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db520a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_df(DB_DIR, DATASET_FILE)\n",
    "y = df['Label']\n",
    "X = df.drop('Label', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7292ac00",
   "metadata": {},
   "source": [
    "### Get feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "379f0de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99500ab5",
   "metadata": {},
   "source": [
    "### Fit label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "492cf06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder().fit(df['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7a0796",
   "metadata": {},
   "source": [
    "### Train-Test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "464e2f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.2)\n",
    "\n",
    "X_train.reset_index(drop = True, inplace = True)\n",
    "X_test.reset_index(drop = True, inplace = True)\n",
    "y_train.reset_index(drop = True, inplace = True)\n",
    "y_test.reset_index(drop = True, inplace = True)\n",
    "\n",
    "train_df = pd.concat([X_train, y_train.rename('Label')], axis = 1)\n",
    "test_df = pd.concat([X_test, y_test.rename('Label')], axis = 1)\n",
    "\n",
    "dump_df(DATASET_DIR, TRAIN_F_NAME, train_df)\n",
    "dump_df(DATASET_DIR, TEST_F_NAME, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d418e227",
   "metadata": {},
   "source": [
    "### Stratified K-fold splitting for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b1e37de",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c3dfc1",
   "metadata": {},
   "source": [
    "# Class balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7974e88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a769785",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_DIR = os.path.join(DATASET_DIR, 'validation')\n",
    "FOLDS_DIR = os.path.join(VALIDATION_DIR, 'fold{}')\n",
    "\n",
    "VALIDATION_DATA_DIR = os.path.join(FOLDS_DIR, 'data')\n",
    "VALIDATION_MODELS_DIR = os.path.join(FOLDS_DIR, 'models')\n",
    "\n",
    "CLUSTER_BAL_SETS_DIR = os.path.join(VALIDATION_DATA_DIR, 'cluster_bal')\n",
    "RANDOM_BAL_SETS_DIR = os.path.join(VALIDATION_DATA_DIR, 'random_bal')\n",
    "\n",
    "CLUSTER_BAL_MODELS_DIR = os.path.join(VALIDATION_MODELS_DIR, 'cluster_bal')\n",
    "RANDOM_BAL_MODELS_DIR = os.path.join(VALIDATION_MODELS_DIR, 'random_bal')\n",
    "\n",
    "CLUSTER_BAL = 'cluster_balancing'\n",
    "RANDOM_BAL = 'random_balancing'\n",
    "ALL = 'all'\n",
    "\n",
    "BALANCED_SET_F_NAME = 'train{}.csv'\n",
    "MODEL_F_NAME = 'clf{}.joblib'\n",
    "\n",
    "MAX = 'max'\n",
    "SUM = 'sum'\n",
    "PRODUCT = 'product'\n",
    "MAJORITY_VOTE = 'majority_vote'\n",
    "VOTE_METHODS = (MAX, SUM, PRODUCT, MAJORITY_VOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f8fa6a",
   "metadata": {},
   "source": [
    "### Cluster based majority class splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e823df5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_splits(majority_df, minority_df, K):\n",
    "    \n",
    "    # Drop label column temporarily\n",
    "    majority_df.drop('Label', inplace = True, axis = 1)\n",
    "    \n",
    "    # Scale features and perform kmeans clustering on the majority class dataset\n",
    "    majority_df_scaled = QuantileTransformer(output_distribution='normal').fit_transform(majority_df)\n",
    "    kmeans = KMeans(n_clusters = K).fit(majority_df_scaled)\n",
    "    majority_df['Cluster ID'] = kmeans.labels_\n",
    "    \n",
    "    # Put label column back\n",
    "    majority_df['Label'] = MAJORITY_CLASS\n",
    "    \n",
    "    # Distribute clusters entries evenly amongst K new datasets\n",
    "    clusters = [cluster for _, cluster in majority_df.groupby(['Cluster ID'])]\n",
    "    splits = [pd.DataFrame() for _ in range(K)]\n",
    "    for cluster in clusters:\n",
    "        cluster.drop('Cluster ID', inplace = True, axis = 1)\n",
    "        for i in range(K):\n",
    "            splits[i] = splits[i].append(cluster.iloc[[j for j in range(i, cluster.shape[0], K)]], ignore_index = True)\n",
    "            \n",
    "    # Append the minority class dataset to each split\n",
    "    split_dfs = [split.append(minority_df, ignore_index = True) for split in splits]\n",
    "            \n",
    "    return split_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4cce14",
   "metadata": {},
   "source": [
    "### Random based majority class splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9730b416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_splits(majority_df, minority_df, K):\n",
    "    \n",
    "    # Shuffle the majority class dataset\n",
    "    majority_df_shuffled = majority_df.sample(frac = 1)\n",
    "    \n",
    "    # split the shuffled dataset\n",
    "    splits = np.array_split(majority_df_shuffled, K) \n",
    "    \n",
    "    # Append the minority class dataset to each split\n",
    "    splits_df = [pd.DataFrame(split).append(minority_df, ignore_index = True) for split in splits]\n",
    "    \n",
    "    return splits_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dd001b",
   "metadata": {},
   "source": [
    "### Balanced datasets creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "517877a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced_datasets(df, method):\n",
    "    \n",
    "    grouped_df = {label: label_df for label, label_df in df.groupby('Label')}\n",
    "    \n",
    "    majority_df = grouped_df[MAJORITY_CLASS]\n",
    "    minority_df = grouped_df[MINORITY_CLASS]\n",
    "\n",
    "    majority_df.reset_index(drop = True, inplace = True)\n",
    "    minority_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    K = round(majority_df.shape[0] / minority_df.shape[0])\n",
    "    \n",
    "    if method == CLUSTER_BAL:\n",
    "        balanced_dfs = get_cluster_splits(majority_df.copy(), minority_df.copy(), K)\n",
    "    elif method == RANDOM_BAL:\n",
    "        balanced_dfs = get_random_splits(majority_df.copy(), minority_df.copy(), K)\n",
    "        \n",
    "    return balanced_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881350f9",
   "metadata": {},
   "source": [
    "### K-fold balanced datasets creation and dumping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70428d98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def dump_balanced_datasets(df, skf, method = ALL):\n",
    "    \n",
    "    y = df['Label']\n",
    "    X = df.drop('Label', axis = 1)\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "\n",
    "        print('============================= Fold {} =============================\\n'.format(fold))\n",
    "\n",
    "        validation_train_df = train_df.iloc[train_index]\n",
    "        validation_test_df = train_df.iloc[test_index]\n",
    "\n",
    "        print('Saving validation test dataset...')\n",
    "\n",
    "        dump_df(VALIDATION_DATA_DIR.format(fold), TEST_F_NAME, validation_test_df)\n",
    "\n",
    "        print('Done!')\n",
    "\n",
    "        print('Creating and saving balanced subsets...')\n",
    "        \n",
    "        if (method == CLUSTER_BAL) or (method == ALL):\n",
    "            \n",
    "            cluster_split_dfs = create_balanced_datasets(validation_train_df, CLUSTER_BAL)\n",
    "            \n",
    "            for i, cluster_split_df in enumerate(cluster_split_dfs):\n",
    "                dump_df(CLUSTER_BAL_SETS_DIR.format(fold), BALANCED_SET_F_NAME.format(i), cluster_split_df)\n",
    "        \n",
    "        if (method == RANDOM_BAL) or (method == ALL):\n",
    "            \n",
    "            random_split_dfs = create_balanced_datasets(validation_train_df, RANDOM_BAL)\n",
    "            \n",
    "            for i, random_split_df in enumerate(random_split_dfs):\n",
    "                dump_df(RANDOM_BAL_SETS_DIR.format(fold), BALANCED_SET_F_NAME.format(i), random_split_df)\n",
    "\n",
    "        print('Done!\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0436db41",
   "metadata": {},
   "source": [
    "### Ensemble Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4edf57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble:\n",
    "    \n",
    "    def __init__(self, le): \n",
    "        \n",
    "        self.le = le\n",
    "        self.clfs = []\n",
    "    \n",
    "    def fit(self, df_list):\n",
    "        \n",
    "        for df in df_list:\n",
    "            \n",
    "            y = df['Label']\n",
    "            X = df.drop('Label', axis = 1)\n",
    "            \n",
    "            clf = RandomForestClassifier(n_estimators = 100, n_jobs =- 1)\n",
    "            clf.fit(X, y)\n",
    "            \n",
    "            self.clfs += [clf]\n",
    "            \n",
    "    def predict(self, X, vote_method = MAX):\n",
    "        \n",
    "        p = np.asarray([clf.predict_proba(X) for clf in self.clfs])\n",
    "        \n",
    "        if vote_method == MAX:\n",
    "            y_pred = self.max_proba(p)\n",
    "            \n",
    "        elif vote_method == SUM:\n",
    "            y_pred = self.sum_proba(p)\n",
    "            \n",
    "        elif vote_method == PRODUCT:\n",
    "            y_pred = self.prod_proba(p)\n",
    "            \n",
    "        elif vote_method == MAJORITY_VOTE:\n",
    "            y_pred = self.majority_vote(p)\n",
    "        \n",
    "        return y_pred\n",
    "            \n",
    "    def max_proba(self, p1):        \n",
    "        p2 = p1.max(axis = 0)\n",
    "        return self.le.inverse_transform(p2.argmax(axis = 1))\n",
    "    \n",
    "    def sum_proba(self, p1):        \n",
    "        p2 = p1.sum(axis = 0)\n",
    "        return self.le.inverse_transform(p2.argmax(axis = 1))\n",
    "    \n",
    "    def prod_proba(self, p1):\n",
    "        p2 = p1.prod(axis = 0)        \n",
    "        return self.le.inverse_transform(p2.argmax(axis = 1))\n",
    "    \n",
    "    def majority_vote(self, p1):        \n",
    "        p2 = np.apply_along_axis(lambda a : np.array([1 if a[0] >= a[1] else 0, 1 if a[1] >= a[0] else 0]), 2, p1)\n",
    "        p3 = p2.sum(axis = 0)\n",
    "        return self.le.inverse_transform(p3.argmax(axis = 1))\n",
    "    \n",
    "    def get_feature_importances(self): \n",
    "        return np.average(np.asarray([clf.feature_importances_ for clf in self.clfs]), axis = 0)\n",
    "    \n",
    "    def save_clfs(self, clfs_dir, f_name):\n",
    "        if not os.path.exists(clfs_dir):\n",
    "            os.makedirs(clfs_dir)\n",
    "        for i, clf in enumerate(self.clfs):\n",
    "            dump(clf, os.path.join(clfs_dir, f_name.format(i)))\n",
    "            \n",
    "    def load_clfs(self, clfs_dir):    \n",
    "        self.clfs = [load(os.path.join(clfs_dir, f_name)) for f_name in os.listdir(clfs_dir)]\n",
    "        \n",
    "    def get_clfs(self):\n",
    "        return self.clfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75f01ac",
   "metadata": {},
   "source": [
    "### Load training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe5b7162",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_df(DATASET_DIR, TRAIN_F_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccb71f1",
   "metadata": {},
   "source": [
    "### Create and dump balanced datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5424192f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= Fold 0 =============================\n",
      "\n",
      "Saving validation test dataset...\n",
      "Done!\n",
      "Creating and saving balanced subsets...\n",
      "Done!\n",
      "\n",
      "============================= Fold 1 =============================\n",
      "\n",
      "Saving validation test dataset...\n",
      "Done!\n",
      "Creating and saving balanced subsets...\n",
      "Done!\n",
      "\n",
      "============================= Fold 2 =============================\n",
      "\n",
      "Saving validation test dataset...\n",
      "Done!\n",
      "Creating and saving balanced subsets...\n",
      "Done!\n",
      "\n",
      "============================= Fold 3 =============================\n",
      "\n",
      "Saving validation test dataset...\n",
      "Done!\n",
      "Creating and saving balanced subsets...\n",
      "Done!\n",
      "\n",
      "============================= Fold 4 =============================\n",
      "\n",
      "Saving validation test dataset...\n",
      "Done!\n",
      "Creating and saving balanced subsets...\n",
      "Done!\n",
      "\n",
      "============================= Fold 5 =============================\n",
      "\n",
      "Saving validation test dataset...\n",
      "Done!\n",
      "Creating and saving balanced subsets...\n",
      "Done!\n",
      "\n",
      "============================= Fold 6 =============================\n",
      "\n",
      "Saving validation test dataset...\n",
      "Done!\n",
      "Creating and saving balanced subsets...\n",
      "Done!\n",
      "\n",
      "============================= Fold 7 =============================\n",
      "\n",
      "Saving validation test dataset...\n",
      "Done!\n",
      "Creating and saving balanced subsets...\n",
      "Done!\n",
      "\n",
      "============================= Fold 8 =============================\n",
      "\n",
      "Saving validation test dataset...\n",
      "Done!\n",
      "Creating and saving balanced subsets...\n",
      "Done!\n",
      "\n",
      "============================= Fold 9 =============================\n",
      "\n",
      "Saving validation test dataset...\n",
      "Done!\n",
      "Creating and saving balanced subsets...\n",
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dump_balanced_datasets(train_df, skf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e421711",
   "metadata": {},
   "source": [
    "### Ensemble training on balanced data implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7757cf50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_ensemble(n_folds, le, method = ALL):\n",
    "\n",
    "    for fold in range(n_folds):\n",
    "\n",
    "        print('============================= Fold {} =============================\\n'.format(fold))\n",
    "\n",
    "        print('Training and saving models...')\n",
    "        \n",
    "        if (method == CLUSTER_BAL) or (method == ALL):\n",
    "            \n",
    "            cluster_bal_dir = CLUSTER_BAL_SETS_DIR.format(fold)\n",
    "            cluster_split_dfs = [load_df(cluster_bal_dir, f_name) for f_name in os.listdir(cluster_bal_dir)]\n",
    "\n",
    "            ensemble_cluster = Ensemble(le)    \n",
    "            ensemble_cluster.fit(cluster_split_dfs)\n",
    "            ensemble_cluster.save_clfs(CLUSTER_BAL_MODELS_DIR.format(fold), MODEL_F_NAME)\n",
    "            \n",
    "        if (method == RANDOM_BAL) or (method == ALL):\n",
    "        \n",
    "            random_bal_dir = RANDOM_BAL_SETS_DIR.format(fold)\n",
    "            random_split_dfs = [load_df(random_bal_dir, f_name) for f_name in os.listdir(random_bal_dir)]\n",
    "\n",
    "            ensemble_random = Ensemble(le)    \n",
    "            ensemble_random.fit(random_split_dfs)\n",
    "            ensemble_random.save_clfs(RANDOM_BAL_MODELS_DIR.format(fold), MODEL_F_NAME)        \n",
    "\n",
    "        print('Done!\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19632248",
   "metadata": {},
   "source": [
    "### Train ensembles on balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17112c21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= Fold 0 =============================\n",
      "\n",
      "Training and saving models...\n",
      "Done!\n",
      "\n",
      "============================= Fold 1 =============================\n",
      "\n",
      "Training and saving models...\n",
      "Done!\n",
      "\n",
      "============================= Fold 2 =============================\n",
      "\n",
      "Training and saving models...\n",
      "Done!\n",
      "\n",
      "============================= Fold 3 =============================\n",
      "\n",
      "Training and saving models...\n",
      "Done!\n",
      "\n",
      "============================= Fold 4 =============================\n",
      "\n",
      "Training and saving models...\n",
      "Done!\n",
      "\n",
      "============================= Fold 5 =============================\n",
      "\n",
      "Training and saving models...\n",
      "Done!\n",
      "\n",
      "============================= Fold 6 =============================\n",
      "\n",
      "Training and saving models...\n",
      "Done!\n",
      "\n",
      "============================= Fold 7 =============================\n",
      "\n",
      "Training and saving models...\n",
      "Done!\n",
      "\n",
      "============================= Fold 8 =============================\n",
      "\n",
      "Training and saving models...\n",
      "Done!\n",
      "\n",
      "============================= Fold 9 =============================\n",
      "\n",
      "Training and saving models...\n",
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_ensemble(skf.get_n_splits(), le)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b2b420",
   "metadata": {},
   "source": [
    "### Evaluation function implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe7ffc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    \n",
    "    n = skf.get_n_splits()\n",
    "\n",
    "    cluster_accuracy = {vote_method: 0 for vote_method in VOTE_METHODS}\n",
    "    cluster_mcc = {vote_method: 0 for vote_method in VOTE_METHODS}\n",
    "    random_accuracy = {vote_method: 0 for vote_method in VOTE_METHODS}\n",
    "    random_mcc = {vote_method: 0 for vote_method in VOTE_METHODS}\n",
    "\n",
    "    for fold in range(n):\n",
    "\n",
    "        print('============================= Fold {} =============================\\n'.format(fold))\n",
    "\n",
    "        print('Loading validation test dataset...')\n",
    "\n",
    "        validation_test_df = load_df(VALIDATION_DATA_DIR.format(fold), TEST_F_NAME)\n",
    "\n",
    "        y_test = validation_test_df['Label']\n",
    "        X_test = validation_test_df.drop('Label', axis = 1)\n",
    "\n",
    "        print('Done!')\n",
    "\n",
    "        print('Loading trained models...')\n",
    "\n",
    "        ensemble_cluster = Ensemble(le)\n",
    "        ensemble_cluster.load_clfs(CLUSTER_BAL_MODELS_DIR.format(fold))\n",
    "\n",
    "        ensemble_random = Ensemble(le)\n",
    "        ensemble_random.load_clfs(RANDOM_BAL_MODELS_DIR.format(fold))\n",
    "\n",
    "        print('Done!')\n",
    "\n",
    "        print('Evaluating predictions...')\n",
    "\n",
    "        for vote_method in VOTE_METHODS:\n",
    "\n",
    "            y_pred_cluster = ensemble_cluster.predict(X_test, vote_method)\n",
    "            cluster_accuracy[vote_method] += accuracy_score(y_test, y_pred_cluster)\n",
    "            cluster_mcc[vote_method] += matthews_corrcoef(y_test, y_pred_cluster)\n",
    "\n",
    "            y_pred_random = ensemble_random.predict(X_test, vote_method)\n",
    "            random_accuracy[vote_method] += accuracy_score(y_test, y_pred_random)\n",
    "            random_mcc[vote_method] += matthews_corrcoef(y_test, y_pred_random)\n",
    "\n",
    "        print('Done!\\n')\n",
    "\n",
    "    print('============================= Results =============================\\n')\n",
    "\n",
    "    for vote_method in VOTE_METHODS:\n",
    "\n",
    "        cluster_accuracy[vote_method] /= n\n",
    "        cluster_mcc[vote_method] /= n\n",
    "        random_accuracy[vote_method] /= n\n",
    "        random_mcc[vote_method] /= n\n",
    "\n",
    "        print('-------------------------- Vote: {} -------------------------\\n'.format(vote_method))\n",
    "        print('Cluster split accuracy: {:.4f}'.format(cluster_accuracy[vote_method]))\n",
    "        print('Cluster split MCC: {:.4f}\\n'.format(cluster_mcc[vote_method]))\n",
    "        print('Random split accuracy: {:.4f}'.format(random_accuracy[vote_method]))\n",
    "        print('Random split MCC: {:.4f}\\n'.format(random_mcc[vote_method]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fc628e",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0de29324",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= Fold 0 =============================\n",
      "\n",
      "Loading validation test dataset...\n",
      "Done!\n",
      "Loading trained models...\n",
      "Done!\n",
      "Evaluating predictions...\n",
      "Done!\n",
      "\n",
      "============================= Fold 1 =============================\n",
      "\n",
      "Loading validation test dataset...\n",
      "Done!\n",
      "Loading trained models...\n",
      "Done!\n",
      "Evaluating predictions...\n",
      "Done!\n",
      "\n",
      "============================= Fold 2 =============================\n",
      "\n",
      "Loading validation test dataset...\n",
      "Done!\n",
      "Loading trained models...\n",
      "Done!\n",
      "Evaluating predictions...\n",
      "Done!\n",
      "\n",
      "============================= Fold 3 =============================\n",
      "\n",
      "Loading validation test dataset...\n",
      "Done!\n",
      "Loading trained models...\n",
      "Done!\n",
      "Evaluating predictions...\n",
      "Done!\n",
      "\n",
      "============================= Fold 4 =============================\n",
      "\n",
      "Loading validation test dataset...\n",
      "Done!\n",
      "Loading trained models...\n",
      "Done!\n",
      "Evaluating predictions...\n",
      "Done!\n",
      "\n",
      "============================= Fold 5 =============================\n",
      "\n",
      "Loading validation test dataset...\n",
      "Done!\n",
      "Loading trained models...\n",
      "Done!\n",
      "Evaluating predictions...\n",
      "Done!\n",
      "\n",
      "============================= Fold 6 =============================\n",
      "\n",
      "Loading validation test dataset...\n",
      "Done!\n",
      "Loading trained models...\n",
      "Done!\n",
      "Evaluating predictions...\n",
      "Done!\n",
      "\n",
      "============================= Fold 7 =============================\n",
      "\n",
      "Loading validation test dataset...\n",
      "Done!\n",
      "Loading trained models...\n",
      "Done!\n",
      "Evaluating predictions...\n",
      "Done!\n",
      "\n",
      "============================= Fold 8 =============================\n",
      "\n",
      "Loading validation test dataset...\n",
      "Done!\n",
      "Loading trained models...\n",
      "Done!\n",
      "Evaluating predictions...\n",
      "Done!\n",
      "\n",
      "============================= Fold 9 =============================\n",
      "\n",
      "Loading validation test dataset...\n",
      "Done!\n",
      "Loading trained models...\n",
      "Done!\n",
      "Evaluating predictions...\n",
      "Done!\n",
      "\n",
      "============================= Results =============================\n",
      "\n",
      "-------------------------- Vote: max -------------------------\n",
      "\n",
      "Cluster split accuracy: 0.9325\n",
      "Cluster split MCC: 0.5889\n",
      "\n",
      "Random split accuracy: 0.9322\n",
      "Random split MCC: 0.5880\n",
      "\n",
      "-------------------------- Vote: sum -------------------------\n",
      "\n",
      "Cluster split accuracy: 0.9220\n",
      "Cluster split MCC: 0.5599\n",
      "\n",
      "Random split accuracy: 0.9218\n",
      "Random split MCC: 0.5593\n",
      "\n",
      "-------------------------- Vote: product -------------------------\n",
      "\n",
      "Cluster split accuracy: 0.9223\n",
      "Cluster split MCC: 0.5607\n",
      "\n",
      "Random split accuracy: 0.9221\n",
      "Random split MCC: 0.5599\n",
      "\n",
      "-------------------------- Vote: majority_vote -------------------------\n",
      "\n",
      "Cluster split accuracy: 0.9212\n",
      "Cluster split MCC: 0.5584\n",
      "\n",
      "Random split accuracy: 0.9203\n",
      "Random split MCC: 0.5553\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdcd4c9",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "\n",
    "### Get feature importance based on previously trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46f6c00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fis = []\n",
    "\n",
    "for fold in range(skf.get_n_splits()):\n",
    "    \n",
    "    ensemble_cluster = Ensemble(le)\n",
    "    ensemble_cluster.load_clfs(CLUSTER_BAL_MODELS_DIR.format(fold))\n",
    "    \n",
    "    fis += [ensemble_cluster.get_feature_importances()]\n",
    "    \n",
    "fis = np.average(np.asarray(fis), axis = 0)\n",
    "fis = pd.DataFrame(fis, index = feature_names, columns = ['Importance'])\n",
    "fis = fis.sort_values('Importance', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af25d0d",
   "metadata": {},
   "source": [
    "### Show the 20 most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9987419d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MW</th>\n",
       "      <td>0.102498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#Heavy atoms</th>\n",
       "      <td>0.056426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synthetic Accessibility</th>\n",
       "      <td>0.049842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MR</th>\n",
       "      <td>0.049327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CYP1A2 inhibitor_Yes</th>\n",
       "      <td>0.036068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CYP1A2 inhibitor_No</th>\n",
       "      <td>0.035597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fraction Csp3</th>\n",
       "      <td>0.034876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CYP2C19 inhibitor_Yes</th>\n",
       "      <td>0.034626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CYP2C19 inhibitor_No</th>\n",
       "      <td>0.034277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPSA</th>\n",
       "      <td>0.028809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iLOGP</th>\n",
       "      <td>0.025168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leadlikeness #violations</th>\n",
       "      <td>0.025039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#H-bond donors</th>\n",
       "      <td>0.024030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log Kp (cm/s)</th>\n",
       "      <td>0.023326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Silicos-IT Log P</th>\n",
       "      <td>0.023156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consensus Log P</th>\n",
       "      <td>0.022279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLOGP</th>\n",
       "      <td>0.022225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Silicos-IT Solubility (mg/ml)</th>\n",
       "      <td>0.021460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESOL Solubility (mol/l)</th>\n",
       "      <td>0.021445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Silicos-IT LogSw</th>\n",
       "      <td>0.021331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Importance\n",
       "MW                               0.102498\n",
       "#Heavy atoms                     0.056426\n",
       "Synthetic Accessibility          0.049842\n",
       "MR                               0.049327\n",
       "CYP1A2 inhibitor_Yes             0.036068\n",
       "CYP1A2 inhibitor_No              0.035597\n",
       "Fraction Csp3                    0.034876\n",
       "CYP2C19 inhibitor_Yes            0.034626\n",
       "CYP2C19 inhibitor_No             0.034277\n",
       "TPSA                             0.028809\n",
       "iLOGP                            0.025168\n",
       "Leadlikeness #violations         0.025039\n",
       "#H-bond donors                   0.024030\n",
       "log Kp (cm/s)                    0.023326\n",
       "Silicos-IT Log P                 0.023156\n",
       "Consensus Log P                  0.022279\n",
       "MLOGP                            0.022225\n",
       "Silicos-IT Solubility (mg/ml)    0.021460\n",
       "ESOL Solubility (mol/l)          0.021445\n",
       "Silicos-IT LogSw                 0.021331"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fis.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672cb000",
   "metadata": {},
   "source": [
    "### Select the 10 most important features in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed773a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = list(fis.head(10).index) + ['Label']\n",
    "train_df = load_df(DATASET_DIR, TRAIN_F_NAME)\n",
    "train_df = train_df[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d517b5",
   "metadata": {},
   "source": [
    "### Create and dump balanced datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a87f885",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= Fold 0 =============================\n",
      "\n",
      "Saving validation test dataset...\n",
      "Done!\n",
      "Creating and saving balanced subsets...\n",
      "Done!\n",
      "\n",
      "============================= Fold 1 =============================\n",
      "\n",
      "Saving validation test dataset...\n",
      "Done!\n",
      "Creating and saving balanced subsets...\n",
      "Done!\n",
      "\n",
      "============================= Fold 2 =============================\n",
      "\n",
      "Saving validation test dataset...\n",
      "Done!\n",
      "Creating and saving balanced subsets...\n",
      "Done!\n",
      "\n",
      "============================= Fold 3 =============================\n",
      "\n",
      "Saving validation test dataset...\n",
      "Done!\n",
      "Creating and saving balanced subsets...\n",
      "Done!\n",
      "\n",
      "============================= Fold 4 =============================\n",
      "\n",
      "Saving validation test dataset...\n",
      "Done!\n",
      "Creating and saving balanced subsets...\n",
      "Done!\n",
      "\n",
      "============================= Fold 5 =============================\n",
      "\n",
      "Saving validation test dataset...\n",
      "Done!\n",
      "Creating and saving balanced subsets...\n",
      "Done!\n",
      "\n",
      "============================= Fold 6 =============================\n",
      "\n",
      "Saving validation test dataset...\n",
      "Done!\n",
      "Creating and saving balanced subsets...\n",
      "Done!\n",
      "\n",
      "============================= Fold 7 =============================\n",
      "\n",
      "Saving validation test dataset...\n",
      "Done!\n",
      "Creating and saving balanced subsets...\n",
      "Done!\n",
      "\n",
      "============================= Fold 8 =============================\n",
      "\n",
      "Saving validation test dataset...\n",
      "Done!\n",
      "Creating and saving balanced subsets...\n",
      "Done!\n",
      "\n",
      "============================= Fold 9 =============================\n",
      "\n",
      "Saving validation test dataset...\n",
      "Done!\n",
      "Creating and saving balanced subsets...\n",
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dump_balanced_datasets(train_df, skf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fe9907",
   "metadata": {},
   "source": [
    "### Train ensemble on balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "038c03f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= Fold 0 =============================\n",
      "\n",
      "Training and saving models...\n",
      "Done!\n",
      "\n",
      "============================= Fold 1 =============================\n",
      "\n",
      "Training and saving models...\n",
      "Done!\n",
      "\n",
      "============================= Fold 2 =============================\n",
      "\n",
      "Training and saving models...\n",
      "Done!\n",
      "\n",
      "============================= Fold 3 =============================\n",
      "\n",
      "Training and saving models...\n",
      "Done!\n",
      "\n",
      "============================= Fold 4 =============================\n",
      "\n",
      "Training and saving models...\n",
      "Done!\n",
      "\n",
      "============================= Fold 5 =============================\n",
      "\n",
      "Training and saving models...\n",
      "Done!\n",
      "\n",
      "============================= Fold 6 =============================\n",
      "\n",
      "Training and saving models...\n",
      "Done!\n",
      "\n",
      "============================= Fold 7 =============================\n",
      "\n",
      "Training and saving models...\n",
      "Done!\n",
      "\n",
      "============================= Fold 8 =============================\n",
      "\n",
      "Training and saving models...\n",
      "Done!\n",
      "\n",
      "============================= Fold 9 =============================\n",
      "\n",
      "Training and saving models...\n",
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_ensemble(skf.get_n_splits(), le)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115cbb72",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4286ce87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= Fold 0 =============================\n",
      "\n",
      "Loading validation test dataset...\n",
      "Done!\n",
      "Loading trained models...\n",
      "Done!\n",
      "Evaluating predictions...\n",
      "Done!\n",
      "\n",
      "============================= Fold 1 =============================\n",
      "\n",
      "Loading validation test dataset...\n",
      "Done!\n",
      "Loading trained models...\n",
      "Done!\n",
      "Evaluating predictions...\n",
      "Done!\n",
      "\n",
      "============================= Fold 2 =============================\n",
      "\n",
      "Loading validation test dataset...\n",
      "Done!\n",
      "Loading trained models...\n",
      "Done!\n",
      "Evaluating predictions...\n",
      "Done!\n",
      "\n",
      "============================= Fold 3 =============================\n",
      "\n",
      "Loading validation test dataset...\n",
      "Done!\n",
      "Loading trained models...\n",
      "Done!\n",
      "Evaluating predictions...\n",
      "Done!\n",
      "\n",
      "============================= Fold 4 =============================\n",
      "\n",
      "Loading validation test dataset...\n",
      "Done!\n",
      "Loading trained models...\n",
      "Done!\n",
      "Evaluating predictions...\n",
      "Done!\n",
      "\n",
      "============================= Fold 5 =============================\n",
      "\n",
      "Loading validation test dataset...\n",
      "Done!\n",
      "Loading trained models...\n",
      "Done!\n",
      "Evaluating predictions...\n",
      "Done!\n",
      "\n",
      "============================= Fold 6 =============================\n",
      "\n",
      "Loading validation test dataset...\n",
      "Done!\n",
      "Loading trained models...\n",
      "Done!\n",
      "Evaluating predictions...\n",
      "Done!\n",
      "\n",
      "============================= Fold 7 =============================\n",
      "\n",
      "Loading validation test dataset...\n",
      "Done!\n",
      "Loading trained models...\n",
      "Done!\n",
      "Evaluating predictions...\n",
      "Done!\n",
      "\n",
      "============================= Fold 8 =============================\n",
      "\n",
      "Loading validation test dataset...\n",
      "Done!\n",
      "Loading trained models...\n",
      "Done!\n",
      "Evaluating predictions...\n",
      "Done!\n",
      "\n",
      "============================= Fold 9 =============================\n",
      "\n",
      "Loading validation test dataset...\n",
      "Done!\n",
      "Loading trained models...\n",
      "Done!\n",
      "Evaluating predictions...\n",
      "Done!\n",
      "\n",
      "============================= Results =============================\n",
      "\n",
      "-------------------------- Vote: max -------------------------\n",
      "\n",
      "Cluster split accuracy: 0.9088\n",
      "Cluster split MCC: 0.5148\n",
      "\n",
      "Random split accuracy: 0.9096\n",
      "Random split MCC: 0.5191\n",
      "\n",
      "-------------------------- Vote: sum -------------------------\n",
      "\n",
      "Cluster split accuracy: 0.8978\n",
      "Cluster split MCC: 0.4949\n",
      "\n",
      "Random split accuracy: 0.8981\n",
      "Random split MCC: 0.4949\n",
      "\n",
      "-------------------------- Vote: product -------------------------\n",
      "\n",
      "Cluster split accuracy: 0.8983\n",
      "Cluster split MCC: 0.4957\n",
      "\n",
      "Random split accuracy: 0.8986\n",
      "Random split MCC: 0.4961\n",
      "\n",
      "-------------------------- Vote: majority_vote -------------------------\n",
      "\n",
      "Cluster split accuracy: 0.8972\n",
      "Cluster split MCC: 0.4930\n",
      "\n",
      "Random split accuracy: 0.8966\n",
      "Random split MCC: 0.4905\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8332025d",
   "metadata": {},
   "source": [
    "# Testing \n",
    "\n",
    "### Testing function implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c02b69e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(train_df, test_df):\n",
    "\n",
    "    print('Creating balanced datasets...')\n",
    "\n",
    "    cluster_split_dfs = create_balanced_datasets(train_df, CLUSTER_BAL)     \n",
    "    random_split_dfs = create_balanced_datasets(train_df, RANDOM_BAL)\n",
    "\n",
    "    print('Done!')\n",
    "\n",
    "    print('Training ensembles...')\n",
    "\n",
    "    ensemble_cluster = Ensemble(le)    \n",
    "    ensemble_cluster.fit(cluster_split_dfs)\n",
    "\n",
    "    ensemble_random = Ensemble(le)    \n",
    "    ensemble_random.fit(random_split_dfs)\n",
    "\n",
    "    print('Done!')\n",
    "\n",
    "    cluster_accuracy = {vote_method: 0 for vote_method in VOTE_METHODS}\n",
    "    cluster_mcc = {vote_method: 0 for vote_method in VOTE_METHODS}\n",
    "    random_accuracy = {vote_method: 0 for vote_method in VOTE_METHODS}\n",
    "    random_mcc = {vote_method: 0 for vote_method in VOTE_METHODS}\n",
    "\n",
    "    y_test = test_df['Label']\n",
    "    X_test = test_df.drop('Label', axis = 1)\n",
    "\n",
    "    print('Evaluating predictions...')\n",
    "\n",
    "    for vote_method in VOTE_METHODS:\n",
    "\n",
    "        y_pred_cluster = ensemble_cluster.predict(X_test, vote_method)\n",
    "        cluster_accuracy[vote_method] = accuracy_score(y_test, y_pred_cluster)\n",
    "        cluster_mcc[vote_method] = matthews_corrcoef(y_test, y_pred_cluster)\n",
    "\n",
    "        y_pred_random = ensemble_random.predict(X_test, vote_method)\n",
    "        random_accuracy[vote_method] = accuracy_score(y_test, y_pred_random)\n",
    "        random_mcc[vote_method] = matthews_corrcoef(y_test, y_pred_random)\n",
    "\n",
    "    print('Done!\\n')\n",
    "\n",
    "    print('============================= Results =============================\\n')\n",
    "\n",
    "    for vote_method in VOTE_METHODS:\n",
    "\n",
    "        print('-------------------------- Vote: {} -------------------------\\n'.format(vote_method))\n",
    "        print('Cluster split accuracy: {:.4f}'.format(cluster_accuracy[vote_method]))\n",
    "        print('Cluster split MCC: {:.4f}\\n'.format(cluster_mcc[vote_method]))\n",
    "        print('Random split accuracy: {:.4f}'.format(random_accuracy[vote_method]))\n",
    "        print('Random split MCC: {:.4f}\\n'.format(random_mcc[vote_method]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ae5671",
   "metadata": {},
   "source": [
    "### Testing - All features selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f9e7e254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating balanced datasets...\n",
      "Done!\n",
      "Training ensembles...\n",
      "Done!\n",
      "Evaluating predictions...\n",
      "Done!\n",
      "\n",
      "============================= Results =============================\n",
      "\n",
      "-------------------------- Vote: max -------------------------\n",
      "\n",
      "Cluster split accuracy: 0.9357\n",
      "Cluster split MCC: 0.6055\n",
      "\n",
      "Random split accuracy: 0.9360\n",
      "Random split MCC: 0.6059\n",
      "\n",
      "-------------------------- Vote: sum -------------------------\n",
      "\n",
      "Cluster split accuracy: 0.9245\n",
      "Cluster split MCC: 0.5722\n",
      "\n",
      "Random split accuracy: 0.9249\n",
      "Random split MCC: 0.5716\n",
      "\n",
      "-------------------------- Vote: product -------------------------\n",
      "\n",
      "Cluster split accuracy: 0.9249\n",
      "Cluster split MCC: 0.5733\n",
      "\n",
      "Random split accuracy: 0.9252\n",
      "Random split MCC: 0.5726\n",
      "\n",
      "-------------------------- Vote: majority_vote -------------------------\n",
      "\n",
      "Cluster split accuracy: 0.9242\n",
      "Cluster split MCC: 0.5702\n",
      "\n",
      "Random split accuracy: 0.9235\n",
      "Random split MCC: 0.5682\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = load_df(DATASET_DIR, TRAIN_F_NAME)\n",
    "test_df = load_df(DATASET_DIR, TEST_F_NAME)\n",
    "\n",
    "test_model(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be80b5d5",
   "metadata": {},
   "source": [
    "### Testing -  Most important features selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a0c410d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating balanced datasets...\n",
      "Done!\n",
      "Training ensembles...\n",
      "Done!\n",
      "Evaluating predictions...\n",
      "Done!\n",
      "\n",
      "============================= Results =============================\n",
      "\n",
      "-------------------------- Vote: max -------------------------\n",
      "\n",
      "Cluster split accuracy: 0.9148\n",
      "Cluster split MCC: 0.5394\n",
      "\n",
      "Random split accuracy: 0.9136\n",
      "Random split MCC: 0.5351\n",
      "\n",
      "-------------------------- Vote: sum -------------------------\n",
      "\n",
      "Cluster split accuracy: 0.9012\n",
      "Cluster split MCC: 0.5081\n",
      "\n",
      "Random split accuracy: 0.9013\n",
      "Random split MCC: 0.5087\n",
      "\n",
      "-------------------------- Vote: product -------------------------\n",
      "\n",
      "Cluster split accuracy: 0.9021\n",
      "Cluster split MCC: 0.5102\n",
      "\n",
      "Random split accuracy: 0.9015\n",
      "Random split MCC: 0.5093\n",
      "\n",
      "-------------------------- Vote: majority_vote -------------------------\n",
      "\n",
      "Cluster split accuracy: 0.8991\n",
      "Cluster split MCC: 0.5024\n",
      "\n",
      "Random split accuracy: 0.9006\n",
      "Random split MCC: 0.5059\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = load_df(DATASET_DIR, TRAIN_F_NAME)\n",
    "test_df = load_df(DATASET_DIR, TEST_F_NAME)\n",
    "\n",
    "train_df = train_df[selected_features]\n",
    "test_df = test_df[selected_features]\n",
    "\n",
    "test_model(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1147ed32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
